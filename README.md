# ğŸ“° Web Scraping - NotÃ­cias do Governo de GoiÃ¡s

Este projeto realiza **web scraping** das notÃ­cias publicadas no portal oficial do **Governo de GoiÃ¡s** (`https://goias.gov.br`), extraindo **tÃ­tulos, links, datas, categorias e conteÃºdos completos** das notÃ­cias.

## ğŸ“Œ Funcionalidades

âœ… Coleta de **tÃ­tulos**, **links** e **datas** das notÃ­cias  
âœ… ExtraÃ§Ã£o do **conteÃºdo completo** de cada notÃ­cia  
âœ… OrganizaÃ§Ã£o dos dados em um **arquivo CSV**  
âœ… Utiliza as bibliotecas **rvest, httr e dplyr** para manipulaÃ§Ã£o dos dados  

---

## ğŸ›  Tecnologias Utilizadas

- **Linguagem:** R
- **Pacotes:** `rvest`, `httr`, `dplyr`
- **Formato de saÃ­da:** `.csv` (valores separados por vÃ­rgula)

---

## ğŸ“‚ Estrutura do CÃ³digo

```
ğŸ“ /  (DiretÃ³rio Raiz)
â”œâ”€â”€ webscraping_goias_gov.R   # CÃ³digo principal do Web Scraping
â””â”€â”€ noticias_goias_gov.csv    # Arquivo de saÃ­da com as notÃ­cias extraÃ­das
```

---

## ğŸš€ Como Executar

### 1ï¸âƒ£ **Instalar os pacotes necessÃ¡rios**
Antes de rodar o script, certifique-se de que os pacotes **rvest**, **httr** e **dplyr** estÃ£o instalados no R. Para instalÃ¡-los, execute:

```r
install.packages(c("rvest", "httr", "dplyr"))
```

### 2ï¸âƒ£ **Executar o Script**
Rode o script `webscraping_goias_gov.R` no RStudio ou diretamente no R:

```r
source("webscraping_goias_gov.R")
```

### 3ï¸âƒ£ **Aguardar a Coleta dos Dados**
O cÃ³digo irÃ¡ percorrer todas as pÃ¡ginas de notÃ­cias do site (`1226 pÃ¡ginas`), coletando os dados e armazenando no arquivo `noticias_goias_gov.csv`.

---

## ğŸ“Š Estrutura do Arquivo de SaÃ­da (`noticias_goias_gov.csv`)

O CSV gerado terÃ¡ a seguinte estrutura:

| TÃ­tulo | Link | PublicaÃ§Ã£o | Ãšltima AtualizaÃ§Ã£o | Categoria | ConteÃºdo |
|--------|------|------------|--------------------|-----------|----------|
| TÃ­tulo da NotÃ­cia | URL da NotÃ­cia | Data de PublicaÃ§Ã£o | Ãšltima AtualizaÃ§Ã£o | Categoria(s) | Texto Completo |

---

## ğŸ›‘ PossÃ­veis Problemas e SoluÃ§Ãµes

### âš ï¸ **Erro de Bloqueio pelo Site**
Se o site bloquear a requisiÃ§Ã£o, tente alterar o **User-Agent** dentro do script:

```r
pagina <- GET(url, add_headers('User-Agent' = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, como Gecko) Chrome/91.0.4472.124 Safari/537.36'))
```

### â³ **O Processo EstÃ¡ Muito Lento?**
- O site pode ter **limites de requisiÃ§Ã£o**, entÃ£o experimente adicionar **pausas** entre as requisiÃ§Ãµes:

```r
Sys.sleep(3)  # Espera 3 segundos antes de carregar a prÃ³xima pÃ¡gina
```

---

ğŸš€ **Pronto para coletar dados!** Se tiver dÃºvidas, me avise! ğŸ˜Š
