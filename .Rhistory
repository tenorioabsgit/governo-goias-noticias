library(rvest)
library(httr)
library(dplyr)
# Função para extrair dados de uma única página
extrair_dados <- function(url) {
pagina <- GET(url, add_headers('User-Agent' = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'))
conteudo <- pagina %>%
content("text") %>%
read_html()
titulos <- conteudo %>%
html_nodes("h2.entry-title a") %>%
html_text()
links <- conteudo %>%
html_nodes("h2.entry-title a") %>%
html_attr("href")
publicacao <- conteudo %>%
html_nodes(".meta-date a .date") %>%
html_text()
ultima_atualizacao <- conteudo %>%
html_nodes(".meta-date a") %>%
html_text()
categoria <- conteudo %>%
html_nodes(".meta-categories .single-cat") %>%
html_text()
# Garantir que todas as listas tenham o mesmo comprimento
n <- length(titulos)
if (length(publicacao) < n) {
publicacao <- c(publicacao, rep(NA, n - length(publicacao)))
}
if (length(ultima_atualizacao) < n) {
ultima_atualizacao <- c(ultima_atualizacao, rep(NA, n - length(ultima_atualizacao)))
}
if (length(categoria) < n) {
categoria <- c(categoria, rep(NA, n - length(categoria)))
}
# Criar um dataframe temporário com os dados extraídos
df_temp <- data.frame(
titulo = titulos,
link = links,
publicacao = publicacao[1:n], # Ajustar tamanho para corresponder a 'n'
ultima_atualizacao = ultima_atualizacao[1:n], # Ajustar tamanho para corresponder a 'n'
categoria = rep(paste(categoria, collapse = ", "), n), # Ajustar para múltiplos valores de categoria
conteudo = NA,
stringsAsFactors = FALSE
)
return(df_temp)
}
# Função para extrair o conteúdo de uma notícia
extrair_conteudo <- function(url) {
pagina <- GET(url, add_headers('User-Agent' = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'))
conteudo <- pagina %>%
content("text") %>%
read_html()
texto <- conteudo %>%
html_nodes(".entry-content p") %>%
html_text() %>%
paste(collapse = " ")
return(texto)
}
# Inicializar dataframe vazio
df_noticias <- data.frame(titulo = character(), link = character(), publicacao = character(), ultima_atualizacao = character(), categoria = character(), conteudo = character(), stringsAsFactors = FALSE)
# Loop para percorrer todas as páginas
for (i in 1:1226) {
url <- paste0("https://goias.gov.br/categoria/noticias/page/", i, "/")
df_temp <- extrair_dados(url)
# Adicionar os dados ao dataframe principal
df_noticias <- bind_rows(df_noticias, df_temp)
# Opção para exibir progresso
print(paste("Página", i, "processada"))
}
# Loop para percorrer todos os links e extrair o conteúdo
for (i in 1:nrow(df_noticias)) {
df_noticias$conteudo[i] <- extrair_conteudo(df_noticias$link[i])
# Opção para exibir progresso
print(paste("Notícia", i, "processada"))
}
View(df_noticias)
library(rvest)
library(httr)
library(dplyr)
# Função para extrair dados de uma única página
extrair_dados <- function(url) {
pagina <- GET(url, add_headers('User-Agent' = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'))
conteudo <- pagina %>%
content("text") %>%
read_html()
titulos <- conteudo %>%
html_nodes("h2.entry-title a") %>%
html_text()
links <- conteudo %>%
html_nodes("h2.entry-title a") %>%
html_attr("href")
publicacao <- conteudo %>%
html_nodes(".meta-date a .date") %>%
html_text()
ultima_atualizacao <- conteudo %>%
html_nodes(".meta-date a") %>%
html_text()
categoria <- conteudo %>%
html_nodes(".meta-categories .single-cat") %>%
html_text()
# Garantir que todas as listas tenham o mesmo comprimento
n <- length(titulos)
if (length(publicacao) < n) {
publicacao <- c(publicacao, rep(NA, n - length(publicacao)))
}
if (length(ultima_atualizacao) < n) {
ultima_atualizacao <- c(ultima_atualizacao, rep(NA, n - length(ultima_atualizacao)))
}
if (length(categoria) < n) {
categoria <- c(categoria, rep(NA, n - length(categoria)))
}
# Criar um dataframe temporário com os dados extraídos
df_temp <- data.frame(
titulo = titulos,
link = links,
publicacao = publicacao[1:n], # Ajustar tamanho para corresponder a 'n'
ultima_atualizacao = ultima_atualizacao[1:n], # Ajustar tamanho para corresponder a 'n'
categoria = rep(paste(categoria, collapse = ", "), n), # Ajustar para múltiplos valores de categoria
conteudo = NA,
stringsAsFactors = FALSE
)
return(df_temp)
}
# Função para extrair o conteúdo de uma notícia
extrair_conteudo <- function(url) {
pagina <- GET(url, add_headers('User-Agent' = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'))
conteudo <- pagina %>%
content("text") %>%
read_html()
texto <- conteudo %>%
html_nodes(".entry-content p") %>%
html_text() %>%
paste(collapse = " ")
return(texto)
}
# Inicializar dataframe vazio
df_noticias <- data.frame(titulo = character(), link = character(), publicacao = character(), ultima_atualizacao = character(), categoria = character(), conteudo = character(), stringsAsFactors = FALSE)
# Loop para percorrer todas as páginas
for (i in 1:1226) {
url <- paste0("https://goias.gov.br/categoria/noticias/page/", i, "/")
df_temp <- extrair_dados(url)
# Adicionar os dados ao dataframe principal
df_noticias <- bind_rows(df_noticias, df_temp)
# Opção para exibir progresso
print(paste("Página", i, "processada"))
}
View(df_noticias)
